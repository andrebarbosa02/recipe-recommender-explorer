{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAC Project 1 (SNA + RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "members = pd.read_csv('data/pp_members.csv')\n",
    "recipes = pd.read_csv('data/pp_recipes.csv')\n",
    "reviews = pd.read_csv('data/pp_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def ing_process(x, ing_or_quant):\n",
    "\n",
    "    try: \n",
    "        ing_list = ast.literal_eval(x)\n",
    "    except:\n",
    "        print(x)\n",
    "        return None    \n",
    "\n",
    "    try:\n",
    "        res = list(ing_list.values())[0]\n",
    "    except:\n",
    "        print(ing_list)\n",
    "        return None\n",
    "    \n",
    "    return [x[ing_or_quant] for x in res]\n",
    "\n",
    "recipes['ingredients_pp'] = recipes['ingredients'].apply(ing_process, args=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['ingredients_pp']\n",
    "recipes['ingredients_pp'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['quantities_pp'] = recipes['ingredients'].apply(ing_process, args=(1,))\n",
    "recipes['quantities_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['ingredients_pp'].apply(type).unique()\n",
    "\n",
    "recipes[recipes['ingredients_pp'].apply(type) == type(None)]\n",
    "\n",
    "recipes = recipes.drop(recipes[recipes['ingredients_pp'].apply(type) == type(None)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "from collections import defaultdict\n",
    "\n",
    "# Create edges for recipes, based on ingredients in common as weight\n",
    "def ing_freq_edge_weight(df,min_weight=0):\n",
    "    ingredients_freq = {}\n",
    "    # frequency of each ingredient save to a dict\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.iloc[i]['ingredients_pp'])):\n",
    "            if df.iloc[i]['ingredients_pp'][j] in ingredients_freq:\n",
    "                ingredients_freq[df.iloc[i]['ingredients_pp'][j]] += 1\n",
    "            else:\n",
    "                ingredients_freq[df.iloc[i]['ingredients_pp'][j]] = 1\n",
    "\n",
    "    print(\"ing freq\", ingredients_freq)\n",
    "    long_df = df.explode('ingredients_pp')\n",
    "    graph_structure = defaultdict(dict)\n",
    "\n",
    "    for ingredient, rows in long_df.groupby('ingredients_pp'):\n",
    "        # Get all unique pairs of recipes containing this ingredient\n",
    "        pairs = itertools.combinations(rows.index.unique(), 2)\n",
    "\n",
    "        # Calculate weight based on ingredient frequency\n",
    "        weight = 1 / ingredients_freq[ingredient]\n",
    "\n",
    "        # Update the graph structure with the weight for each pair\n",
    "        for a, b in pairs:\n",
    "            if b in graph_structure[a]:\n",
    "                graph_structure[a][b] += weight\n",
    "                graph_structure[b][a] += weight\n",
    "            else:\n",
    "                graph_structure[a][b] = weight\n",
    "                graph_structure[b][a] = weight\n",
    "\n",
    "    # Convert the graph structure to a list of tuples [(index1, index2, weight), ...]\n",
    "    index_pairs = [(a, b, graph_structure[a][b]) for a in graph_structure for b in graph_structure[a] if (a < b) and (graph_structure[a][b]>=min_weight)]\n",
    "\n",
    "    pairs_df = pd.DataFrame(index_pairs, columns=['from', 'to','weight'])\n",
    "    return pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 39)\n",
    "\n",
    "# get the top 1000 recipes with the most ratings\n",
    "top_recipes = recipes.sort_values(by='number_of_ratings', ascending=False)[0:1000]\n",
    "\n",
    "top_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import Graph, plot\n",
    "\n",
    "links = ing_freq_edge_weight(top_recipes)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "net = Graph.DataFrame(links, directed=False, use_vids=False,vertices=top_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = net.es['weight']\n",
    "\n",
    "min_weight = min(weights)\n",
    "max_weight = max(weights)\n",
    "\n",
    "print(min_weight, max_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster detection algorithm\n",
    "clusters = net.community_multilevel(weights=net.es['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_titles = net.vs['title']\n",
    "\n",
    "# Print the clusters with node titles\n",
    "for i, cluster in enumerate(clusters):\n",
    "    node_titles_in_cluster = [node_titles[node_id] for node_id in cluster]\n",
    "    no_of_recipes = len(node_titles_in_cluster)\n",
    "    if no_of_recipes > 1:\n",
    "        print(f\"[{i}] ({no_of_recipes}) {' || '.join(node_titles_in_cluster)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_clusters = len(set(clusters.membership))\n",
    "print(num_clusters)\n",
    "\n",
    "# Generate random colors for clusters\n",
    "vertex_colors = [plt.cm.tab10(i) for i in np.linspace(0, 1, num_clusters)]\n",
    "\n",
    "# Plot the graph with clusters highlighted\n",
    "plot(net, target=\"plots/graph_ingredients_clusters.png\", vertex_size=5, vertex_color=vertex_colors, edge_width=0.1, edge_arrow_size=0.4 ,arrow_width=1, bbox=(0,0,1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = [len(cluster) for cluster in clusters]\n",
    "print(cluster_sizes)\n",
    "\n",
    "plt.hist(cluster_sizes, bins=range(0, 400, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layout based on community membership\n",
    "layout = net.layout_fruchterman_reingold()\n",
    "\n",
    "# Plot each cluster separately\n",
    "for i, cluster in enumerate(clusters):\n",
    "    subgraph = net.subgraph(cluster)\n",
    "\n",
    "    if(len(subgraph.vs) < 5): # minimum number of nodes in a cluster\n",
    "        continue\n",
    "\n",
    "    plot(subgraph, target=f\"plots/cluster_{i}.png\", vertex_size=5, vertex_color=vertex_colors[i], edge_width=0.1, edge_arrow_size=0.4, arrow_width=1, bbox=(0,0,500,500), layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of recipes: {len(top_recipes)}\")\n",
    "\n",
    "def create_reviews_dict(recipes_ids):\n",
    "    top_reviews = reviews[reviews['recipe_id'].isin(recipes_ids)]\n",
    "    reviews_dict = top_reviews.groupby('recipe_id').apply(lambda x: list(zip(x['member_id'], x['rating']))).to_dict()\n",
    "    return top_reviews, reviews_dict\n",
    "    \n",
    "\n",
    "top_reviews, reviews_dict = create_reviews_dict(top_recipes['new_recipe_id'])\n",
    "\n",
    "# Sparsity\n",
    "sparsity = len(top_reviews) / (len(top_recipes) * len(top_reviews['member_id'].unique()))\n",
    "\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get largest cluster\n",
    "top_cluster = max(clusters, key=len)\n",
    "print(len(top_cluster))\n",
    "\n",
    "# get the ids in the top cluster\n",
    "top_cluster_ids = [net.vs[node_id]['new_recipe_id'] for node_id in top_cluster]\n",
    "top_cluster_ids\n",
    "\n",
    "# network_reviews, network_reviews_dict = create_reviews_dict(top_recipes['new_recipe_id'])\n",
    "cluster_reviews, cluster_reviews_dict = create_reviews_dict(top_cluster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for the cluster dictionary\n",
    "def create_ratings_df(ratings_dict):\n",
    "    ratings_rows = []\n",
    "    for recipe_id, ratings in ratings_dict.items():\n",
    "        for member_id, rating in ratings:\n",
    "            ratings_rows.append((member_id, recipe_id, rating))\n",
    "\n",
    "    ratings_df = pd.DataFrame(ratings_rows, columns=['member_id', 'recipe_id', 'rating'])\n",
    "    return ratings_df\n",
    "\n",
    "ratings_sample_df = create_ratings_df(cluster_reviews_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD, KNNWithMeans, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Find maximum and minimum rating\n",
    "max_rating = ratings_sample_df['rating'].max()\n",
    "min_rating = ratings_sample_df['rating'].min()\n",
    "print(max_rating, min_rating)\n",
    "\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "\n",
    "data = Dataset.load_from_df(ratings_sample_df, reader)\n",
    "\n",
    "print(data.df.head())\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select user from top cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_uid = 0\n",
    "\n",
    "for (member, recipe, rating) in ratings_sample_df.values: \n",
    "    if recipe in top_cluster_ids and recipe != 9533:\n",
    "        ref_uid = member\n",
    "        break\n",
    "\n",
    "print(int(ref_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tf-idf for description terms to identify similarities between descriptions and as a result similarity between recipes. Given a recipe, suggest others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content-based filtering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_recipes_filtered = top_recipes.dropna(subset=['description'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "item_features = tfidf_vectorizer.fit_transform(top_recipes_filtered['description'])\n",
    "\n",
    "cosine_sim = cosine_similarity(item_features, item_features)\n",
    "\n",
    "top_n_indices = np.argsort(-cosine_sim, axis=1)[:, 1:21]\n",
    "\n",
    "top_n_recipe_ids = top_recipes_filtered['new_recipe_id'].values[top_n_indices]\n",
    "\n",
    "similar_recipes_dict = {recipe_id: top_n_recipe_ids[i].tolist() for i, recipe_id in enumerate(top_recipes_filtered['new_recipe_id'])}\n",
    "\n",
    "list(similar_recipes_dict.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 similar recipes for a specific recipe\n",
    "recipe_id = 205530\n",
    "similar_recipe_ids = similar_recipes_dict[recipe_id]\n",
    "similar_recipe_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recipe entry for the recipe_id\n",
    "recipe = top_recipes_filtered[top_recipes_filtered['new_recipe_id'] == recipe_id]\n",
    "recipe2 = top_recipes_filtered[top_recipes_filtered['new_recipe_id'] == similar_recipe_ids[1]]\n",
    "\n",
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a user recommend a given number of recipes based on what he liked\n",
    "def recommend_recipes(user_id, n_recipes=10):\n",
    "    user_ratings = ratings_sample_df[ratings_sample_df['member_id'] == user_id]\n",
    "\n",
    "    rated_recipe_ids = user_ratings['recipe_id'].values\n",
    "\n",
    "    top_rated_recipes = user_ratings[user_ratings['rating'] > 3]['recipe_id'].values\n",
    "\n",
    "    print(user_ratings)\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for recipe_id in top_rated_recipes:\n",
    "        similar_recipe_ids = similar_recipes_dict[recipe_id]\n",
    "        print(\"AA\", similar_recipe_ids)\n",
    "        for similar_recipe_id in similar_recipe_ids:\n",
    "            if similar_recipe_id not in rated_recipe_ids:\n",
    "                recommendations.append(similar_recipe_id)\n",
    "\n",
    "        if len(recommendations) >= n_recipes * 20:\n",
    "            break\n",
    "\n",
    "    recommendations = top_recipes[top_recipes['new_recipe_id'].isin(recommendations)].sort_values(by='average_rating', ascending=False).head(n_recipes)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "content_normal = recommend_recipes(ref_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering for the top cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_cluster_recipes = top_recipes[top_recipes['new_recipe_id'].isin(top_cluster_ids)]\n",
    "\n",
    "top_recipes_top_cluster_filtered = top_cluster_recipes.dropna(subset=['description'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "item_features = tfidf_vectorizer.fit_transform(top_recipes_top_cluster_filtered['description'])\n",
    "\n",
    "cosine_sim = cosine_similarity(item_features, item_features)\n",
    "\n",
    "top_n_indices = np.argsort(-cosine_sim, axis=1)[:, 1:21]\n",
    "\n",
    "top_n_recipe_ids = top_recipes_top_cluster_filtered['new_recipe_id'].values[top_n_indices]\n",
    "\n",
    "similar_recipes_cluster_dict = {recipe_id: top_n_recipe_ids[i].tolist() for i, recipe_id in enumerate(top_recipes_top_cluster_filtered['new_recipe_id'])}\n",
    "\n",
    "list(similar_recipes_cluster_dict.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_recipes_top_cluster(user_id, n_recipes=10):\n",
    "    user_ratings = ratings_sample_df[ratings_sample_df['member_id'] == user_id]\n",
    "\n",
    "    rated_recipe_ids = user_ratings['recipe_id'].values\n",
    "\n",
    "    top_rated_recipes = user_ratings[user_ratings['rating'] > 3]['recipe_id'].values\n",
    "\n",
    "    top_rated_recipes = np.intersect1d(top_rated_recipes, top_cluster_ids)\n",
    "\n",
    "    print(user_ratings)\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for recipe_id in top_rated_recipes:\n",
    "        similar_recipe_ids = similar_recipes_cluster_dict[recipe_id]\n",
    "        print(\"AA\", similar_recipe_ids)\n",
    "        for similar_recipe_id in similar_recipe_ids:\n",
    "            if similar_recipe_id not in rated_recipe_ids:\n",
    "                recommendations.append(similar_recipe_id)\n",
    "\n",
    "        if len(recommendations) >= n_recipes * 20:\n",
    "            break\n",
    "\n",
    "    # get top recipes based on rating \n",
    "    recommendations = top_recipes[top_recipes['new_recipe_id'].isin(recommendations)].sort_values(by='average_rating', ascending=False).head(n_recipes)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "content_cluster = recommend_recipes_top_cluster(ref_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparition between cluster vs normal content recommendation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_normal[['title', 'description', 'average_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_cluster[['title', 'description', 'average_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans, SVD\n",
    "from surprise import accuracy\n",
    "\n",
    "def calculate_precision_recall(predictions, threshold=4):\n",
    "    tp = fp = fn = 0\n",
    "\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        if est >= threshold: \n",
    "            if true_r >= threshold:\n",
    "                tp += 1  \n",
    "            else:\n",
    "                fp += 1 \n",
    "        else: \n",
    "            if true_r >= threshold:\n",
    "                fn += 1 \n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluate_algorithm(algo, trainset, testset):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    precision, recall, f1 = calculate_precision_recall(predictions)\n",
    "    return algo, rmse, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item based collaborative filtering\n",
    "algo_svd = SVD()\n",
    "algo_knn_item = KNNWithMeans(sim_options={'name': 'cosine', 'user_based': False})\n",
    "algo_knn_item2 = KNNWithMeans(sim_options={'name': 'pearson', 'user_based': False})\n",
    "\n",
    "model_svd, rmse_svd, precision_svd, recall_svd, f1_svd = evaluate_algorithm(algo_svd, trainset, testset)\n",
    "model_knn, rmse_knn, precision_knn, recall_knn, f1_knn = evaluate_algorithm(algo_knn_item, trainset, testset)   \n",
    "model_knn2, rmse_knn2, precision_knn2, recall_knn2, f1_knn2 = evaluate_algorithm(algo_knn_item2, trainset, testset)\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(f\"SVD RMSE: {rmse_svd}\")\n",
    "print(f\"SVD Precision: {precision_svd}\")\n",
    "print(f\"SVD Recall: {recall_svd}\")\n",
    "print(f\"SVD F1: {f1_svd}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN RMSE: {rmse_knn}\")\n",
    "print(f\"KNN Precision: {precision_knn}\")\n",
    "print(f\"KNN Recall: {recall_knn}\")\n",
    "print(f\"KNN F1: {f1_knn}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN2 RMSE: {rmse_knn2}\")\n",
    "print(f\"KNN2 Precision: {precision_knn2}\")\n",
    "print(f\"KNN2 Recall: {recall_knn2}\")\n",
    "print(f\"KNN2 F1: {f1_knn2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User based collaborative filtering\n",
    "algo_knn_user = KNNWithMeans(sim_options={'name': 'cosine', 'user_based': True})\n",
    "algo_knn_user2 = KNNWithMeans(sim_options={'name': 'pearson', 'user_based': True})\n",
    "\n",
    "model_knn_user, rmse_knn_user, precision_knn_user, recall_knn_user, f1_knn_user = evaluate_algorithm(algo_knn_user, trainset, testset)\n",
    "model_knn_user2, rmse_knn_user2, precision_knn_user2, recall_knn_user2, f1_knn_user2 = evaluate_algorithm(algo_knn_user2, trainset, testset)\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN User RMSE: {rmse_knn_user}\")\n",
    "print(f\"KNN User Precision: {precision_knn_user}\")\n",
    "print(f\"KNN User Recall: {recall_knn_user}\")\n",
    "print(f\"KNN User F1: {f1_knn_user}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN User2 RMSE: {rmse_knn_user2}\")\n",
    "print(f\"KNN User2 Precision: {precision_knn_user2}\")\n",
    "print(f\"KNN User2 Recall: {recall_knn_user2}\")\n",
    "print(f\"KNN User2 F1: {f1_knn_user2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict ratings for user-item pairs using a given model. If a user-item pair has a known rating in the input data, it retains that rating, otherwise, it predicts a rating using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_seen = trainset.all_users()\n",
    "items_seen = trainset.all_items()\n",
    "\n",
    "raw_users_seen_ids = [trainset.to_raw_uid(uid) for uid in users_seen]\n",
    "raw_items_seen_ids = [trainset.to_raw_iid(iid) for iid in items_seen]\n",
    "\n",
    "user_test_id = 1\n",
    "\n",
    "# Check if a user is in the training set\n",
    "if user_test_id in raw_users_seen_ids:\n",
    "    print(f\"User {user_test_id} is in the training set\")\n",
    "else:\n",
    "    print(f\"User {user_test_id} is not in the training set\")\n",
    "\n",
    "    user_test_id = min(raw_users_seen_ids, key=lambda x: np.mean([r for (_, r) in trainset.ur[trainset.to_inner_uid(x)]]))    \n",
    "\n",
    "    print(f\" selecting user {user_test_id} instead\")\n",
    "\n",
    "\n",
    "def predict_ratings(model, raw_users, raw_items, data):\n",
    "    predictions = {}\n",
    "    # Add to the predictions dictionary all ratings that were previously known\n",
    "    for user_id, item_id, rating in data.itertuples(index=False):\n",
    "        predictions[(user_id, item_id)] = rating\n",
    "\n",
    "    # Save the predictions to file\n",
    "    with open('predictions.csv', 'w') as f:\n",
    "        for (user_id, item_id), rating in predictions.items():\n",
    "            f.write(f\"{user_id},{item_id},{rating}\\n\")\n",
    "    \n",
    "\n",
    "    for user_id in raw_users:\n",
    "        if user_id == 311157:\n",
    "            print(\"user_id\", user_id)\n",
    "        for item_id in raw_items:\n",
    "            if (user_id, item_id) not in predictions:\n",
    "                prediction = model.predict(user_id, item_id)\n",
    "                predictions[(user_id, item_id)] = prediction.est\n",
    "\n",
    "    with open('final_predictions.csv', 'w') as f:\n",
    "        for (user_id, item_id), rating in predictions.items():\n",
    "            f.write(f\"{user_id},{item_id},{rating}\\n\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item based\n",
    "pred_svd = predict_ratings(model_svd, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)\n",
    "pred_knn = predict_ratings(model_knn, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)\n",
    "pred_knn2 = predict_ratings(model_knn2, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User based\n",
    "pred_knn_user = predict_ratings(model_knn_user, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)\n",
    "pred_knn_user2 = predict_ratings(model_knn_user2, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top-N Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 recommendations for a user from the ones he hasn't rated yet\n",
    "def get_top_n_recommendations(predictions, user_id, data, n=5):\n",
    "\n",
    "    items_not_rated = data[data['member_id'] != user_id]['recipe_id'].unique()\n",
    "    print(len(items_not_rated))\n",
    "\n",
    "    user_predictions = [(iid, pred) for (uid, iid), pred in predictions.items() if uid == user_id and iid in items_not_rated]   \n",
    "\n",
    "    items_rated = data[data['member_id'] == user_id]['recipe_id'].unique()\n",
    "    print(len(items_rated))\n",
    "\n",
    "    user_ratings = [(iid, pred) for (uid, iid), pred in predictions.items() if uid == user_id and iid in items_rated] \n",
    "\n",
    "    print(len(user_predictions))\n",
    "    user_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return user_predictions[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_svd = get_top_n_recommendations(pred_svd, user_test_id, ratings_sample_df,20)\n",
    "top_n_knn = get_top_n_recommendations(pred_knn, user_test_id, ratings_sample_df,20)\n",
    "top_n_knn2 = get_top_n_recommendations(pred_knn2, user_test_id, ratings_sample_df,20)\n",
    "\n",
    "print(\"User ID:\", user_test_id)\n",
    "print(\"--------------------\")\n",
    "print(\"SVD: \", top_n_svd)\n",
    "print(\"KNN: \", top_n_knn)\n",
    "print(\"KNN2: \", top_n_knn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_knn_user = get_top_n_recommendations(pred_knn_user, user_test_id, ratings_sample_df,20)\n",
    "top_n_knn_user2 = get_top_n_recommendations(pred_knn_user2, user_test_id, ratings_sample_df,20)\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(\"KNN User: \", top_n_knn_user)\n",
    "print(\"KNN User2: \", top_n_knn_user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ratings_sample_df ratings distribution\n",
    "plt.hist(ratings_sample_df['rating'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_item_svd = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_svd])][['title', 'description', 'average_rating']]\n",
    "results_item_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_item_knn = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn])][['title', 'description', 'average_rating']]\n",
    "results_item_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_item_knn2 = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn2])][['title', 'description', 'average_rating']]\n",
    "results_item_knn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_user_knn = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn_user])][['title', 'description', 'average_rating']]\n",
    "results_user_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_user_knn2 = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn_user2])][['title', 'description', 'average_rating']]\n",
    "results_user_knn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 498271\n",
    "user_ratings = ratings_sample_df[ratings_sample_df['member_id'] == uid]\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_liked = top_recipes[top_recipes['new_recipe_id'].isin(user_ratings['recipe_id'])][['title', 'ingredients', 'average_rating']]\n",
    "recipes_liked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svd_user = get_top_n_recommendations(pred_svd, uid, ratings_sample_df, 20)\n",
    "pred_knn_user = get_top_n_recommendations(pred_knn, uid, ratings_sample_df, 20)\n",
    "pred_knn_user2 = get_top_n_recommendations(pred_knn2, uid, ratings_sample_df, 20)\n",
    "pred_svd_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified the following ingredients as relevant: \n",
    "- chicken \n",
    "- tortilla\n",
    "- chips\n",
    "- tomatoes\n",
    "- cheese\n",
    "- spaghetti pasta\n",
    "- pepper\n",
    "- tomato sauce\n",
    "- ground beef\n",
    "- green beans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_svd = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in pred_svd_user])].sort_values(by='average_rating', ascending=False)\n",
    "recipes_svd[['title', 'ingredients', 'average_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_svd['relevant'] = [1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1]\n",
    "recipes_svd[['title', 'relevant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_knn = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in pred_knn_user])].sort_values(by='average_rating', ascending=False)\n",
    "recipes_knn[['title', 'ingredients', 'average_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_knn2 = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in pred_knn_user2])].sort_values(by='average_rating', ascending=False)\n",
    "recipes_knn2[['title', 'ingredients', 'average_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a sample of the dataset to test the NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_recipes_by_amount = recipes.sort_values(by='number_of_ratings', ascending=False)[0:10000]\n",
    "pln_recipes_by_dates = recipes.sort_values(by='last_changed_date', ascending=False)[0:10000]\n",
    "pln_recipes_by_amount = pln_recipes_by_amount.sort_values(by='last_changed_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning of the data and removal of empty values. Also selects which attributes to use in the model. It has different modes:\n",
    "1) 'ingredients': uses only the ingredients\n",
    "2) 'description': uses only the description\n",
    "3) 'all': uses both ingredients and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_select_attributes(df, attributes_mode):\n",
    "    df = df.dropna(subset=['description','ingredients_pp'])\n",
    "    if attributes_mode == 1:\n",
    "        df['attributes'] = df['description']\n",
    "    elif attributes_mode == 2:\n",
    "        df['attributes'] = df.apply(lambda row: ' '.join(map(str,row['ingredients_pp'])),axis=1)\n",
    "    elif attributes_mode == 3:\n",
    "        df['attributes'] = df.apply(lambda row: ''.join(row['description'] + ' ' + ' '.join(map(str,row['ingredients_pp']))), axis=1)\n",
    "    text_sample = df['attributes']\n",
    "    text_sample.index = df['last_changed_date']\n",
    "    return text_sample, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_description_text_sample, amount_description_df = clean_select_attributes(pln_recipes_by_amount, 1)\n",
    "amount_ingredients_text_sample, amount_ingredients_df = clean_select_attributes(pln_recipes_by_amount, 2)\n",
    "amount_both_text_sample, amount_both_df = clean_select_attributes(pln_recipes_by_amount, 3)\n",
    "\n",
    "dates_description_text_sample, dates_description_df = clean_select_attributes(pln_recipes_by_dates, 1)\n",
    "dates_ingredients_text_sample, dates_ingredients_df = clean_select_attributes(pln_recipes_by_dates, 2)\n",
    "dates_both_text_sample, dates_both_df = clean_select_attributes(pln_recipes_by_dates, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for the model, using PLN techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Utilizador\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Utilizador\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def clean_text_lemmatization(text_sample):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sw = set(stopwords.words('english'))\n",
    "    text_sample = text_sample.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "    text_sample = text_sample.apply(lambda x: x.lower())\n",
    "    text_sample = text_sample.apply(lambda x: ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in x.split() if w not in sw]))\n",
    "    return text_sample\n",
    "\n",
    "def clean_text_stemming(text_sample):\n",
    "    ps = PorterStemmer()\n",
    "    sw = set(stopwords.words('english'))\n",
    "    text_sample = text_sample.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "    text_sample = text_sample.apply(lambda x: x.lower())\n",
    "    text_sample = text_sample.apply(lambda x: ' '.join([ps.stem(w) for w in x.split() if w not in sw]))\n",
    "    return text_sample\n",
    "\n",
    "def clean_text_tokenization(text_sample):\n",
    "    sw = set(stopwords.words('english'))\n",
    "    text_sample = text_sample.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "    text_sample = text_sample.apply(lambda x: x.lower())\n",
    "    text_sample = text_sample.apply(lambda x: [w for w in x.split() if w not in sw])\n",
    "    return text_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_amount_description_text_sample = clean_text_tokenization(amount_description_text_sample)\n",
    "tokenized_amount_ingredients_text_sample = clean_text_tokenization(amount_ingredients_text_sample)\n",
    "tokenized_amount_both_text_sample = clean_text_tokenization(amount_both_text_sample)\n",
    "\n",
    "tokenized_dates_description_text_sample = clean_text_tokenization(dates_description_text_sample)\n",
    "tokenized_dates_ingredients_text_sample = clean_text_tokenization(dates_ingredients_text_sample)\n",
    "tokenized_dates_both_text_sample = clean_text_tokenization(dates_both_text_sample)\n",
    "\n",
    "lemmatized_amount_description_text_sample = clean_text_lemmatization(amount_description_text_sample)\n",
    "lemmatized_amount_ingredients_text_sample = clean_text_lemmatization(amount_ingredients_text_sample)\n",
    "lemmatized_amount_both_text_sample = clean_text_lemmatization(amount_both_text_sample)\n",
    "\n",
    "lemmatized_dates_description_text_sample = clean_text_lemmatization(dates_description_text_sample)\n",
    "lemmatized_dates_ingredients_text_sample = clean_text_lemmatization(dates_ingredients_text_sample)\n",
    "lemmatized_dates_both_text_sample = clean_text_lemmatization(dates_both_text_sample)\n",
    "\n",
    "stemmed_amount_description_text_sample = clean_text_stemming(amount_description_text_sample)\n",
    "stemmed_amount_ingredients_text_sample = clean_text_stemming(amount_ingredients_text_sample)\n",
    "stemmed_amount_both_text_sample = clean_text_stemming(amount_both_text_sample)\n",
    "\n",
    "stemmed_dates_description_text_sample = clean_text_stemming(dates_description_text_sample)\n",
    "stemmed_dates_ingredients_text_sample = clean_text_stemming(dates_ingredients_text_sample)\n",
    "stemmed_dates_both_text_sample = clean_text_stemming(dates_both_text_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply vectorizer####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "def get_matrix(text_sample, vectorizer):\n",
    "    matrix = vectorizer.fit_transform(text_sample)\n",
    "    return matrix, vectorizer\n",
    "\n",
    "count_tokenized_amount_description_matrix, count_tokenized_amount_description_vectorizer = get_matrix(tokenized_amount_description_text_sample, count_vectorizer)\n",
    "count_tokenized_amount_ingredients_matrix, count_tokenized_amount_ingredients_vectorizer = get_matrix(tokenized_amount_ingredients_text_sample, count_vectorizer)\n",
    "count_tokenized_amount_both_matrix, count_tokenized_amount_both_vectorizer = get_matrix(tokenized_amount_both_text_sample, count_vectorizer)\n",
    "\n",
    "count_tokenized_dates_description_matrix, count_tokenized_dates_description_vectorizer = get_matrix(tokenized_dates_description_text_sample, count_vectorizer)\n",
    "count_tokenized_dates_ingredients_matrix, count_tokenized_dates_ingredients_vectorizer = get_matrix(tokenized_dates_ingredients_text_sample, count_vectorizer)\n",
    "count_tokenized_dates_both_matrix, count_tokenized_dates_both_vectorizer = get_matrix(tokenized_dates_both_text_sample, count_vectorizer)\n",
    "\n",
    "tfidf_tokenized_amount_description_matrix, tfidf_tokenized_amount_description_vectorizer = get_matrix(tokenized_amount_description_text_sample, tfidf_vectorizer)\n",
    "tfidf_tokenized_amount_ingredients_matrix, tfidf_tokenized_amount_ingredients_vectorizer = get_matrix(tokenized_amount_ingredients_text_sample, tfidf_vectorizer)\n",
    "tfidf_tokenized_amount_both_matrix, tfidf_tokenized_amount_both_vectorizer = get_matrix(tokenized_amount_both_text_sample, tfidf_vectorizer)\n",
    "\n",
    "tfidf_tokenized_dates_description_matrix, tfidf_tokenized_dates_description_vectorizer = get_matrix(tokenized_dates_description_text_sample, tfidf_vectorizer)\n",
    "tfidf_tokenized_dates_ingredients_matrix, tfidf_tokenized_dates_ingredients_vectorizer = get_matrix(tokenized_dates_ingredients_text_sample, tfidf_vectorizer)\n",
    "tfidf_tokenized_dates_both_matrix, tfidf_tokenized_dates_both_vectorizer = get_matrix(tokenized_dates_both_text_sample, tfidf_vectorizer)\n",
    "\n",
    "count_lemmatized_amount_description_matrix, count_lemmatized_amount_description_vectorizer = get_matrix(lemmatized_amount_description_text_sample, count_vectorizer)\n",
    "count_lemmatized_amount_ingredients_matrix, count_lemmatized_amount_ingredients_vectorizer = get_matrix(lemmatized_amount_ingredients_text_sample, count_vectorizer)\n",
    "count_lemmatized_amount_both_matrix, count_lemmatized_amount_both_vectorizer = get_matrix(lemmatized_amount_both_text_sample, count_vectorizer)\n",
    "\n",
    "count_lemmatized_dates_description_matrix, count_lemmatized_dates_description_vectorizer = get_matrix(lemmatized_dates_description_text_sample, count_vectorizer)\n",
    "count_lemmatized_dates_ingredients_matrix, count_lemmatized_dates_ingredients_vectorizer = get_matrix(lemmatized_dates_ingredients_text_sample, count_vectorizer)\n",
    "count_lemmatized_dates_both_matrix, count_lemmatized_dates_both_vectorizer = get_matrix(lemmatized_dates_both_text_sample, count_vectorizer)\n",
    "\n",
    "tfidf_lemmatized_amount_description_matrix, tfidf_lemmatized_amount_description_vectorizer = get_matrix(lemmatized_amount_description_text_sample, tfidf_vectorizer)\n",
    "tfidf_lemmatized_amount_ingredients_matrix, tfidf_lemmatized_amount_ingredients_vectorizer = get_matrix(lemmatized_amount_ingredients_text_sample, tfidf_vectorizer)\n",
    "tfidf_lemmatized_amount_both_matrix, tfidf_lemmatized_amount_both_vectorizer = get_matrix(lemmatized_amount_both_text_sample, tfidf_vectorizer)\n",
    "\n",
    "tfidf_lemmatized_dates_description_matrix, tfidf_lemmatized_dates_description_vectorizer = get_matrix(lemmatized_dates_description_text_sample, tfidf_vectorizer)\n",
    "tfidf_lemmatized_dates_ingredients_matrix, tfidf_lemmatized_dates_ingredients_vectorizer = get_matrix(lemmatized_dates_ingredients_text_sample, tfidf_vectorizer)\n",
    "tfidf_lemmatized_dates_both_matrix, tfidf_lemmatized_dates_both_vectorizer = get_matrix(lemmatized_dates_both_text_sample, tfidf_vectorizer)\n",
    "\n",
    "count_stemmed_amount_description_matrix, count_stemmed_amount_description_vectorizer = get_matrix(stemmed_amount_description_text_sample, count_vectorizer)\n",
    "count_stemmed_amount_ingredients_matrix, count_stemmed_amount_ingredients_vectorizer = get_matrix(stemmed_amount_ingredients_text_sample, count_vectorizer)\n",
    "count_stemmed_amount_both_matrix, count_stemmed_amount_both_vectorizer = get_matrix(stemmed_amount_both_text_sample, count_vectorizer)\n",
    "\n",
    "count_stemmed_dates_description_matrix, count_stemmed_dates_description_vectorizer = get_matrix(stemmed_dates_description_text_sample, count_vectorizer)\n",
    "count_stemmed_dates_ingredients_matrix, count_stemmed_dates_ingredients_vectorizer = get_matrix(stemmed_dates_ingredients_text_sample, count_vectorizer)\n",
    "count_stemmed_dates_both_matrix, count_stemmed_dates_both_vectorizer = get_matrix(stemmed_dates_both_text_sample, count_vectorizer)\n",
    "\n",
    "tfidf_stemmed_amount_description_matrix, tfidf_stemmed_amount_description_vectorizer = get_matrix(stemmed_amount_description_text_sample, tfidf_vectorizer)\n",
    "tfidf_stemmed_amount_ingredients_matrix, tfidf_stemmed_amount_ingredients_vectorizer = get_matrix(stemmed_amount_ingredients_text_sample, tfidf_vectorizer)\n",
    "tfidf_stemmed_amount_both_matrix, tfidf_stemmed_amount_both_vectorizer = get_matrix(stemmed_amount_both_text_sample, tfidf_vectorizer)\n",
    "\n",
    "tfidf_stemmed_dates_description_matrix, tfidf_stemmed_dates_description_vectorizer = get_matrix(stemmed_dates_description_text_sample, tfidf_vectorizer)\n",
    "tfidf_stemmed_dates_ingredients_matrix, tfidf_stemmed_dates_ingredients_vectorizer = get_matrix(stemmed_dates_ingredients_text_sample, tfidf_vectorizer)\n",
    "tfidf_stemmed_dates_both_matrix, tfidf_stemmed_dates_both_vectorizer = get_matrix(stemmed_dates_both_text_sample, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "n_topics = 10\n",
    "\n",
    "def get_keys(topic_matrix):\n",
    "    keys = topic_matrix.argmax(axis=1).tolist()\n",
    "    return keys\n",
    "def keys_to_counts(keys):\n",
    "    count_pairs = sorted(Counter(keys).items())\n",
    "    print(count_pairs)\n",
    "    categories = [pair[0] for pair in sorted(count_pairs)]\n",
    "    counts = [pair[1] for pair in sorted(count_pairs)]\n",
    "    return (categories, counts)\n",
    "\n",
    "def get_top_n_words(n, keys, document_term_matrix, count_vectorizer):\n",
    "    '''\n",
    "    Returns a list of n_topic strings, where each string contains the n most common \n",
    "    words in a predicted category, in order.\n",
    "    '''\n",
    "    top_words = []\n",
    "    n_topics = np.unique(keys).size  # Ensure you know the number of unique topics\n",
    "\n",
    "    for topic in range(n_topics):\n",
    "        # Initialize a zero vector of the same shape as a row in your document_term_matrix\n",
    "        temp_vector_sum = np.zeros((1, document_term_matrix.shape[1]))\n",
    "        for i in range(len(keys)):\n",
    "            if keys[i] == topic:\n",
    "                # Increment by the row corresponding to the document associated with the topic\n",
    "                temp_vector_sum += document_term_matrix[i].toarray()  # convert sparse matrix row to dense\n",
    "\n",
    "        # Extract the indices of the top n words; these are the columns in the matrix\n",
    "        top_n_word_indices = np.flip(np.argsort(temp_vector_sum)[0][-n:], 0)\n",
    "        \n",
    "        # Retrieve the actual words from the count_vectorizer\n",
    "        topic_words = [count_vectorizer.get_feature_names_out()[index] for index in top_n_word_indices]\n",
    "        top_words.append(\" \".join(topic_words))\n",
    "    \n",
    "    return top_words\n",
    "\n",
    "def get_mean_topic_vectors(keys, two_dim_vectors):\n",
    "    '''\n",
    "    returns a list of centroid vectors from each predicted topic category\n",
    "    '''\n",
    "    mean_topic_vectors = []\n",
    "    for t in range(n_topics):\n",
    "        articles_in_that_topic = []\n",
    "        for i in range(len(keys)):\n",
    "            if keys[i] == t:\n",
    "                #print(t, two_dim_vectors[i])\n",
    "                articles_in_that_topic.append(two_dim_vectors[i])    \n",
    "        print(articles_in_that_topic)\n",
    "        articles_in_that_topic = np.vstack(articles_in_that_topic)\n",
    "        mean_article_in_that_topic = np.mean(articles_in_that_topic, axis=0)\n",
    "        mean_topic_vectors.append(mean_article_in_that_topic)\n",
    "    return mean_topic_vectors\n",
    "\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\" ])\n",
    "colormap = colormap[:n_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics, learning_method='online', \n",
    "                                          random_state=0, verbose=0)\n",
    "lda_topic_matrix = lda_model.fit_transform(count_tokenized_amount_description_matrix)\n",
    "lda_keys = get_keys(lda_topic_matrix)\n",
    "lda_categories, lda_counts = keys_to_counts(lda_keys)\n",
    "top_n_words_lda = get_top_n_words(10, lda_keys, count_tokenized_amount_description_matrix, count_tokenized_amount_description_vectorizer)\n",
    "\n",
    "for i in range(len(top_n_words_lda)):\n",
    "    print(\"Topic {}: \".format(i+1), top_n_words_lda[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_3_words_lda = get_top_n_words(3, lda_keys, count_tokenized_amount_description_matrix, count_tokenized_amount_description_vectorizer)\n",
    "labels = ['Topic {}: \\n'.format(i) + top_3_words_lda[i] for i in range(len(top_3_words_lda))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.bar(lda_categories, lda_counts)\n",
    "ax.set_xticks(lda_categories)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('LDA topic counts')\n",
    "ax.set_ylabel('Number of headlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_lda_model = TSNE(n_components=2, perplexity=50, learning_rate=100, \n",
    "                        n_iter=2000, verbose=1, random_state=0, angle=0.75)\n",
    "tsne_lda_vectors = tsne_lda_model.fit_transform(lda_topic_matrix)\n",
    "lda_mean_topic_vectors = get_mean_topic_vectors(lda_keys, tsne_lda_vectors)\n",
    "print(len(lda_keys))\n",
    "print(len(tsne_lda_vectors))\n",
    "print(lda_mean_topic_vectors)\n",
    "\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), width=700, height=700)\n",
    "plot.scatter(x=tsne_lda_vectors[:,0], y=tsne_lda_vectors[:,1], color=colormap[lda_keys])\n",
    "\n",
    "for t in range(n_topics):\n",
    "    label = Label(x=lda_mean_topic_vectors[t][0], y=lda_mean_topic_vectors[t][1], \n",
    "                  text=top_3_words_lda[t], text_color=colormap[t])\n",
    "    plot.add_layout(label)\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Reviews from the top topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_topic_recipes_ids = [i for i in range(len(lda_keys)) if lda_keys[i] == lda_counts.index(max(lda_counts))]\n",
    "topic_reviews, topic_reviews_dict = create_reviews_dict(largest_topic_recipes_ids)\n",
    "ratings_topics_sample_df = create_ratings_df(topic_reviews_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sorted(list(cluster_reviews['last_modified_date']))\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_until_date(reviews, date):\n",
    "    filtered_reviews = reviews[reviews['last_modified_date'] <= date]\n",
    "    return len(filtered_reviews)\n",
    "\n",
    "reviews_until_date(cluster_reviews, dates[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_count = pd.DataFrame([[date, reviews_until_date(cluster_reviews, date)] for date in dates], columns=['Date', 'Count']).drop_duplicates()\n",
    "review_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_between_dates(reviews, initial_date, end_date):\n",
    "    filtered_reviews = reviews[(reviews['last_modified_date'] > initial_date) & (reviews['last_modified_date'] <= end_date)]\n",
    "    return len(filtered_reviews)\n",
    "\n",
    "\n",
    "def bin_dates(dataset, bin_size=20): \n",
    "    first_date = dataset['last_modified_date'].min()\n",
    "    last_date = dataset['last_modified_date'].max()\n",
    "\n",
    "    bin_range = (pd.to_datetime(last_date) - pd.to_datetime(first_date)) / bin_size\n",
    "\n",
    "    bins = [pd.to_datetime(first_date) + bin_range * i for i in range(bin_size)]\n",
    "\n",
    "    for i in range(len(bins)):  \n",
    "        bins[i] = bins[i].strftime('%Y-%m-%d')\n",
    "\n",
    "    bins.append(last_date)\n",
    "\n",
    "    return bins  \n",
    "\n",
    "\n",
    "dates = bin_dates(cluster_reviews)\n",
    "\n",
    "binned_reviews = []\n",
    "for i in range(len(dates) - 1):\n",
    "    initial_date = dates[i]\n",
    "    end_date = dates[i + 1]\n",
    "    reviews_count = reviews_between_dates(cluster_reviews, initial_date, end_date)\n",
    "    binned_reviews.append({'start_date': initial_date, 'end_date': end_date, 'review_count': reviews_count})\n",
    "\n",
    "binned_reviews_df = pd.DataFrame(binned_reviews)\n",
    "print(binned_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Count', dpi=100):\n",
    "    plt.figure(figsize=(15,4), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red', )\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(binned_reviews_df, x=binned_reviews_df['start_date'], y=binned_reviews_df['review_count'], title='Temporal Analysis of Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def plot_decompositions(df, label, period=10): \n",
    "    # Multiplicative Decomposition \n",
    "    multiplicative_decomposition = seasonal_decompose(df[label], model='multiplicative', period=period)\n",
    "\n",
    "    # Additive Decomposition\n",
    "    additive_decomposition = seasonal_decompose(df[label], model='additive', period=period)\n",
    "\n",
    "    # Plot\n",
    "    plt.rcParams.update({'figure.figsize': (16,12)})\n",
    "    multiplicative_decomposition.plot().suptitle('Multiplicative Decomposition', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    additive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decompositions(binned_reviews_df, 'review_count', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decompositions(review_count, 'Count', period=len(review_count) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rating_between_dates(reviews, initial_date, end_date):\n",
    "    filtered_reviews = reviews[(reviews['last_modified_date'] > initial_date) & (reviews['last_modified_date'] <= end_date)]\n",
    "    return filtered_reviews['rating'].mean()\n",
    "\n",
    "def average_rating_until_date(reviews, date):\n",
    "    filtered_reviews = reviews[reviews['last_modified_date'] <= date]\n",
    "    return filtered_reviews['rating'].mean()\n",
    "\n",
    "def bin_dates(dataset, bin_size=20):\n",
    "    first_date = dataset['last_modified_date'].min()\n",
    "    last_date = dataset['last_modified_date'].max()\n",
    "\n",
    "    bin_range = (pd.to_datetime(last_date) - pd.to_datetime(first_date)) / bin_size\n",
    "\n",
    "    bins = [pd.to_datetime(first_date) + bin_range * i for i in range(bin_size)]\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        bins[i] = bins[i].strftime('%Y-%m-%d')\n",
    "\n",
    "    bins.append(last_date)\n",
    "\n",
    "    return bins\n",
    "\n",
    "dates = bin_dates(cluster_reviews, 50)\n",
    "\n",
    "binned_ratings = []\n",
    "\n",
    "for i in range(len(dates) - 1):\n",
    "    initial_date = dates[i]\n",
    "    end_date = dates[i + 1]\n",
    "    average_rating = average_rating_between_dates(cluster_reviews, initial_date, end_date)\n",
    "    binned_ratings.append({'start_date': initial_date, 'end_date': end_date, 'average_rating': average_rating})\n",
    "\n",
    "binned_ratings_df = pd.DataFrame(binned_ratings)\n",
    "print(binned_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_ratings_df['average_rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decompositions(binned_ratings_df, 'average_rating', period=len(binned_ratings_df) // 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of the popularity of a recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on historical data, attempt to predict the popularity of a recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# was using cluster_reviews previously bit changed to top recipes' reviews\n",
    "top_reviews = reviews[reviews['recipe_id'].isin(top_recipes['new_recipe_id'])]\n",
    "\n",
    "def aggregate_reviews(review_data, time_interval='daily'):\n",
    "\n",
    "    new_review_data = review_data.copy()\n",
    "\n",
    "    new_review_data['last_modified_date'] = pd.to_datetime(review_data['last_modified_date'])\n",
    "\n",
    "    new_review_data.set_index('last_modified_date', inplace=True)\n",
    "\n",
    "    if time_interval == 'daily':\n",
    "        aggregated_data = new_review_data.groupby(['recipe_id', pd.Grouper(freq='D')]).agg({\n",
    "            'rating': 'mean',\n",
    "            'likes': 'sum',\n",
    "            'review_id': 'count'  # counting reviews\n",
    "        }).reset_index()\n",
    "\n",
    "    elif time_interval == 'weekly':\n",
    "        aggregated_data = new_review_data.groupby(['recipe_id', pd.Grouper(freq='W-MON')]).agg({\n",
    "            'rating': 'mean',\n",
    "            'likes': 'sum',\n",
    "            'review_id': 'count'\n",
    "        }).reset_index()\n",
    "\n",
    "    elif time_interval == 'monthly':\n",
    "        aggregated_data = new_review_data.groupby(['recipe_id', pd.Grouper(freq='M')]).agg({\n",
    "            'rating': 'mean',\n",
    "            'likes': 'sum',\n",
    "            'review_id': 'count'\n",
    "        }).reset_index()\n",
    "\n",
    "    aggregated_data = aggregated_data.rename(columns={'review_id': 'review_count'})\n",
    "\n",
    "    return aggregated_data\n",
    "\n",
    "daily_reviews = aggregate_reviews(top_reviews, time_interval='daily')\n",
    "weekly_reviews = aggregate_reviews(top_reviews, time_interval='weekly')\n",
    "monthly_reviews = aggregate_reviews(top_reviews, time_interval='monthly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure correlation between rating, likes, and review count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_daily = daily_reviews[['rating', 'likes', 'review_count']].corr()\n",
    "corr_matrix_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr_coefficient_likes_rating = daily_reviews['likes'].corr(daily_reviews['rating'])\n",
    "pearson_corr_coefficient_likes_review_count = daily_reviews['likes'].corr(daily_reviews['review_count'])\n",
    "pearson_corr_coefficient_rating_review_count = daily_reviews['rating'].corr(daily_reviews['review_count'])\n",
    "\n",
    "print(\"\\nPearson Correlation Coefficients:\")\n",
    "print(\"Likes - Average Rating:\", pearson_corr_coefficient_likes_rating)\n",
    "print(\"Likes - Review Count:\", pearson_corr_coefficient_likes_review_count)\n",
    "print(\"Average Rating - Review Count:\", pearson_corr_coefficient_rating_review_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spearman rank coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_corr_coefficient_likes_rating, _ = spearmanr(daily_reviews['likes'], daily_reviews['rating'])\n",
    "spearman_corr_coefficient_likes_review_count, _ = spearmanr(daily_reviews['likes'], daily_reviews['review_count'])\n",
    "spearman_corr_coefficient_rating_review_count, _ = spearmanr(daily_reviews['rating'], daily_reviews['review_count'])\n",
    "\n",
    "print(\"\\nSpearman Rank Correlation Coefficients:\")\n",
    "print(\"Likes - Average Rating:\", spearman_corr_coefficient_likes_rating)\n",
    "print(\"Likes - Review Count:\", spearman_corr_coefficient_likes_review_count)\n",
    "print(\"Average Rating - Review Count:\", spearman_corr_coefficient_rating_review_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_weekly = weekly_reviews[['rating', 'likes', 'review_count']].corr()\n",
    "corr_matrix_weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr_coefficient_likes_rating = weekly_reviews['likes'].corr(weekly_reviews['rating'])\n",
    "pearson_corr_coefficient_likes_review_count = weekly_reviews['likes'].corr(weekly_reviews['review_count'])\n",
    "pearson_corr_coefficient_rating_review_count = weekly_reviews['rating'].corr(weekly_reviews['review_count'])\n",
    "\n",
    "print(\"\\nPearson Correlation Coefficients:\")\n",
    "print(\"Likes - Average Rating:\", pearson_corr_coefficient_likes_rating)\n",
    "print(\"Likes - Review Count:\", pearson_corr_coefficient_likes_review_count)\n",
    "print(\"Average Rating - Review Count:\", pearson_corr_coefficient_rating_review_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spearman rank coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_corr_coefficient_likes_rating, _ = spearmanr(weekly_reviews['likes'], weekly_reviews['rating'])\n",
    "spearman_corr_coefficient_likes_review_count, _ = spearmanr(weekly_reviews['likes'], weekly_reviews['review_count'])\n",
    "spearman_corr_coefficient_rating_review_count, _ = spearmanr(weekly_reviews['rating'], weekly_reviews['review_count'])\n",
    "\n",
    "print(\"\\nSpearman Rank Correlation Coefficients:\")\n",
    "print(\"Likes - Average Rating:\", spearman_corr_coefficient_likes_rating)\n",
    "print(\"Likes - Review Count:\", spearman_corr_coefficient_likes_review_count)\n",
    "print(\"Average Rating - Review Count:\", spearman_corr_coefficient_rating_review_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_monthly = monthly_reviews[['rating', 'likes', 'review_count']].corr()\n",
    "corr_matrix_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr_coefficient_likes_rating = monthly_reviews['likes'].corr(monthly_reviews['rating'])\n",
    "pearson_corr_coefficient_likes_review_count = monthly_reviews['likes'].corr(monthly_reviews['review_count'])\n",
    "pearson_corr_coefficient_rating_review_count = monthly_reviews['rating'].corr(monthly_reviews['review_count'])\n",
    "\n",
    "print(\"\\nPearson Correlation Coefficients:\")\n",
    "print(\"Likes - Average Rating:\", pearson_corr_coefficient_likes_rating)\n",
    "print(\"Likes - Review Count:\", pearson_corr_coefficient_likes_review_count)\n",
    "print(\"Average Rating - Review Count:\", pearson_corr_coefficient_rating_review_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spearman rank coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearman_corr_coefficient_likes_rating, _ = spearmanr(monthly_reviews['likes'], monthly_reviews['rating'])\n",
    "spearman_corr_coefficient_likes_review_count, _ = spearmanr(monthly_reviews['likes'], monthly_reviews['review_count'])\n",
    "spearman_corr_coefficient_rating_review_count, _ = spearmanr(monthly_reviews['rating'], monthly_reviews['review_count'])\n",
    "\n",
    "print(\"\\nSpearman Rank Correlation Coefficients:\")\n",
    "print(\"Likes - Average Rating:\", spearman_corr_coefficient_likes_rating)\n",
    "print(\"Likes - Review Count:\", spearman_corr_coefficient_likes_review_count)\n",
    "print(\"Average Rating - Review Count:\", spearman_corr_coefficient_rating_review_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions on variable dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Correlation matrix we can conclude that overall there is a: \n",
    "- Negative correlation between review count and rating. \n",
    "- Slightly negative correlation between like count and rating.\n",
    "- Slightly positive correlation between like count and review count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = monthly_reviews.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating more relavant features for modeling and achieve better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likes to reviews ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['likes_to_reviews_ratio'] = dataset['likes'] / dataset['review_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likes to rating ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['likes_to_rating_ratio'] = dataset['likes'] / dataset['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'rating': 0.2,\n",
    "    'likes': 0.4,\n",
    "    'review_count': 0.4,\n",
    "    'likes_to_reviews_ratio': 0.1,\n",
    "    'likes_to_rating_ratio': 0.1\n",
    "}\n",
    "\n",
    "# normalize features\n",
    "normalized_features = (dataset[['rating', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio']] - dataset[['rating', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio']].min()) / (dataset[['rating', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio']].max() - dataset[['rating', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio']].min())\n",
    "\n",
    "dataset['popularity_score'] = (normalized_features['rating'] * weights['rating']) + (normalized_features['likes'] * weights['likes']) + (normalized_features['review_count'] * weights['review_count']) + (normalized_features['likes_to_reviews_ratio'] * weights['likes_to_reviews_ratio']) + (normalized_features['likes_to_rating_ratio'] * weights['likes_to_rating_ratio'])\n",
    "\n",
    "'''\n",
    "daily_reviews['popularity_rank'] = daily_reviews['popularity_score'].rank(ascending=False)\n",
    "\n",
    "top_popular_recipes = daily_reviews.sort_values(by='popularity_rank').head(10)\n",
    "print(top_popular_recipes[['recipe_id', 'popularity_score', 'popularity_rank']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New look of dataset with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing dataset for making predictions about the possible popularity of a recipe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting date to day, month and year categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['last_modified_date'] = pd.to_datetime(dataset['last_modified_date'])\n",
    "\n",
    "dataset['day'] = dataset['last_modified_date'].dt.day\n",
    "dataset['month'] = dataset['last_modified_date'].dt.month\n",
    "dataset['year'] = dataset['last_modified_date'].dt.year\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting most relevant features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataset[['rating', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio', 'popularity_score', \n",
    "                            'day', 'month', 'year']].corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = dataset[['rating', 'last_modified_date', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio', \n",
    "                        'popularity_score']]\n",
    "\n",
    "modeling_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = modeling_data.sort_values(by=['last_modified_date'], ascending=False)\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "split_index = int(len(data_sorted) * test_size)\n",
    "\n",
    "test_data = data_sorted.iloc[:split_index]\n",
    "train_data = data_sorted.iloc[split_index:]\n",
    "\n",
    "train_data = train_data.sort_values(by=['last_modified_date'])\n",
    "test_data = test_data.sort_values(by=['last_modified_date'])\n",
    "\n",
    "print(\"Training set size:\", len(train_data))\n",
    "print(\"Testing set size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train the ARIMA model\n",
    "p, d, q = 1, 1, 1 \n",
    "arima_model = ARIMA(train_data['popularity_score'], order=(p, d, q))\n",
    "arima_model_fit = arima_model.fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_arima = arima_model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions_arima)\n",
    "\n",
    "'''\n",
    "import itertools\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define ranges for p, d, and q values\n",
    "p_values = range(0, 4)  # Example range for p\n",
    "d_values = range(0, 4)  # Example range for d\n",
    "q_values = range(0, 4)  # Example range for q\n",
    "\n",
    "# Create a grid of hyperparameters\n",
    "param_grid = list(itertools.product(p_values, d_values, q_values))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "# Assuming train_data and validation_data are already defined\n",
    "# You may need to define these variables appropriately\n",
    "# Also, ensure that the 'popularity_score' column exists in both train_data and validation_data\n",
    "\n",
    "# Initialize variables to store best model and its performance\n",
    "best_model = None\n",
    "best_mse = float('inf')  # Initialize with a large value\n",
    "\n",
    "# Perform grid search\n",
    "for param in param_grid:\n",
    "    p, d, q = param\n",
    "    try:\n",
    "        # Train ARIMA model with current hyperparameters on the training set\n",
    "        arima_model = ARIMA(train_data['popularity_score'], order=(p, d, q))\n",
    "        arima_model_fit = arima_model.fit()\n",
    "\n",
    "        # Make predictions on the validation set\n",
    "        predictions_arima = arima_model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "        # Calculate Mean Squared Error (MSE) on the validation set\n",
    "        mse = mean_squared_error(test_data['popularity_score'], predictions_arima)\n",
    "\n",
    "        # Update best model if current model has lower MSE\n",
    "        if mse < best_mse:\n",
    "            best_model = arima_model_fit\n",
    "            best_mse = mse\n",
    "\n",
    "    except:\n",
    "        continue'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p, d, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(predictions_arima)\n",
    "plt.title('Predictions Plot')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "'''\n",
    "# Ensure 'last_modified_date' is a datetime column\n",
    "train_data['last_modified_date'] = pd.to_datetime(train_data['last_modified_date'])\n",
    "test_data['last_modified_date'] = pd.to_datetime(test_data['last_modified_date'])\n",
    "\n",
    "# Set 'last_modified_date' as the index\n",
    "train_data.set_index('last_modified_date', inplace=True)\n",
    "test_data.set_index('last_modified_date', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(train_data.isna().sum())\n",
    "print(test_data.isna().sum())\n",
    "\n",
    "# Ensure no missing values\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()'''\n",
    "\n",
    "# Train the Simple Exponential Smoothing model\n",
    "ses_model = SimpleExpSmoothing(train_data['popularity_score'])\n",
    "ses_model_fit = ses_model.fit(smoothing_level=0.2, optimized=True)  # You can adjust the smoothing_level\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_es = ses_model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions_es)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(test_data['popularity_score'], predictions_es)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Display the model summary\n",
    "print(ses_model_fit.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(predictions_es)\n",
    "plt.title('Predictions Plot')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing a different dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While ARIMA and Exponential Smoothing models are able to capture temporal information, ML models like RF are not able to interpret this information. As such, we need to convert the date variable into categorical attributes in order for the RF to be able to interpret and analyze this information better. For example, instead of having a timestamp representing dates, we could convert that timestamp in 3 categorical attributes, them being day, month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "modeling_data = dataset.sort_values(by=['last_modified_date'], ascending=True)\n",
    "modeling_data = modeling_data[['recipe_id', 'rating', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio', 'popularity_score', 'day', 'month', 'year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA and Exponential Smoothing are designed for time series data, but RF is not. So one good suggestion would be to shift the target variable, popularity_score, so that it can handle time data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data['popularity_score'] = modeling_data['popularity_score'].shift(1)\n",
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = modeling_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(modeling_data, test_size=0.2, shuffle=False)\n",
    "\n",
    "features = ['rating', 'likes', 'review_count', 'likes_to_reviews_ratio', 'likes_to_rating_ratio', 'day', 'month', 'year']\n",
    "target = 'popularity_score'\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# r2 score\n",
    "r2 = rf_model.score(X_test, y_test)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "# measure accuracy \n",
    "accuracy = rf_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Optional: Print feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(modeling_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
