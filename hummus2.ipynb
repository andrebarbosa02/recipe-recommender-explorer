{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAC Project 1 (SNA + RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "members = pd.read_csv('data/pp_members.csv')\n",
    "recipes = pd.read_csv('data/pp_recipes.csv')\n",
    "reviews = pd.read_csv('data/pp_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def ing_process(x, ing_or_quant):\n",
    "\n",
    "    try: \n",
    "        ing_list = ast.literal_eval(x)\n",
    "    except:\n",
    "        print(x)\n",
    "        return None    \n",
    "\n",
    "    try:\n",
    "        res = list(ing_list.values())[0]\n",
    "    except:\n",
    "        print(ing_list)\n",
    "        return None\n",
    "    \n",
    "    return [x[ing_or_quant] for x in res]\n",
    "\n",
    "recipes['ingredients_pp'] = recipes['ingredients'].apply(ing_process, args=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['ingredients_pp']\n",
    "recipes['ingredients_pp'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['quantities_pp'] = recipes['ingredients'].apply(ing_process, args=(1,))\n",
    "recipes['quantities_pp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['ingredients_pp'].apply(type).unique()\n",
    "\n",
    "recipes[recipes['ingredients_pp'].apply(type) == type(None)]\n",
    "\n",
    "recipes = recipes.drop(recipes[recipes['ingredients_pp'].apply(type) == type(None)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "from collections import defaultdict\n",
    "\n",
    "# Create edges for recipes, based on ingredients in common as weight\n",
    "def ing_freq_edge_weight(df,min_weight=0):\n",
    "    ingredients_freq = {}\n",
    "    # frequency of each ingredient save to a dict\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.iloc[i]['ingredients_pp'])):\n",
    "            if df.iloc[i]['ingredients_pp'][j] in ingredients_freq:\n",
    "                ingredients_freq[df.iloc[i]['ingredients_pp'][j]] += 1\n",
    "            else:\n",
    "                ingredients_freq[df.iloc[i]['ingredients_pp'][j]] = 1\n",
    "\n",
    "    print(\"ing freq\", ingredients_freq)\n",
    "    long_df = df.explode('ingredients_pp')\n",
    "    graph_structure = defaultdict(dict)\n",
    "\n",
    "    for ingredient, rows in long_df.groupby('ingredients_pp'):\n",
    "        # Get all unique pairs of recipes containing this ingredient\n",
    "        pairs = itertools.combinations(rows.index.unique(), 2)\n",
    "\n",
    "        # Calculate weight based on ingredient frequency\n",
    "        weight = 1 / ingredients_freq[ingredient]\n",
    "\n",
    "        # Update the graph structure with the weight for each pair\n",
    "        for a, b in pairs:\n",
    "            if b in graph_structure[a]:\n",
    "                graph_structure[a][b] += weight\n",
    "                graph_structure[b][a] += weight\n",
    "            else:\n",
    "                graph_structure[a][b] = weight\n",
    "                graph_structure[b][a] = weight\n",
    "\n",
    "    # Convert the graph structure to a list of tuples [(index1, index2, weight), ...]\n",
    "    index_pairs = [(a, b, graph_structure[a][b]) for a in graph_structure for b in graph_structure[a] if (a < b) and (graph_structure[a][b]>=min_weight)]\n",
    "\n",
    "    pairs_df = pd.DataFrame(index_pairs, columns=['from', 'to','weight'])\n",
    "    return pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 39)\n",
    "\n",
    "# get the top 1000 recipes with the most ratings\n",
    "top_recipes = recipes.sort_values(by='number_of_ratings', ascending=False)[0:1000]\n",
    "\n",
    "top_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import Graph, plot\n",
    "\n",
    "links = ing_freq_edge_weight(top_recipes)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "net = Graph.DataFrame(links, directed=False, use_vids=False,vertices=top_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = net.es['weight']\n",
    "\n",
    "min_weight = min(weights)\n",
    "max_weight = max(weights)\n",
    "\n",
    "print(min_weight, max_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster detection algorithm\n",
    "clusters = net.community_multilevel(weights=net.es['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_titles = net.vs['title']\n",
    "\n",
    "# Print the clusters with node titles\n",
    "for i, cluster in enumerate(clusters):\n",
    "    node_titles_in_cluster = [node_titles[node_id] for node_id in cluster]\n",
    "    no_of_recipes = len(node_titles_in_cluster)\n",
    "    if no_of_recipes > 1:\n",
    "        print(f\"[{i}] ({no_of_recipes}) {' || '.join(node_titles_in_cluster)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_clusters = len(set(clusters.membership))\n",
    "print(num_clusters)\n",
    "\n",
    "# Generate random colors for clusters\n",
    "vertex_colors = [plt.cm.tab10(i) for i in np.linspace(0, 1, num_clusters)]\n",
    "\n",
    "# Plot the graph with clusters highlighted\n",
    "plot(net, target=\"plots/graph_ingredients_clusters.png\", vertex_size=5, vertex_color=vertex_colors, edge_width=0.1, edge_arrow_size=0.4 ,arrow_width=1, bbox=(0,0,1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = [len(cluster) for cluster in clusters]\n",
    "print(cluster_sizes)\n",
    "\n",
    "plt.hist(cluster_sizes, bins=range(0, 400, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layout based on community membership\n",
    "layout = net.layout_fruchterman_reingold()\n",
    "\n",
    "# Plot each cluster separately\n",
    "for i, cluster in enumerate(clusters):\n",
    "    subgraph = net.subgraph(cluster)\n",
    "\n",
    "    if(len(subgraph.vs) < 5): # minimum number of nodes in a cluster\n",
    "        continue\n",
    "\n",
    "    plot(subgraph, target=f\"plots/cluster_{i}.png\", vertex_size=5, vertex_color=vertex_colors[i], edge_width=0.1, edge_arrow_size=0.4, arrow_width=1, bbox=(0,0,500,500), layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of recipes: {len(top_recipes)}\")\n",
    "\n",
    "def create_reviews_dict(recipes_ids):\n",
    "    top_reviews = reviews[reviews['recipe_id'].isin(recipes_ids)]\n",
    "    reviews_dict = top_reviews.groupby('recipe_id').apply(lambda x: list(zip(x['member_id'], x['rating']))).to_dict()\n",
    "    return top_reviews, reviews_dict\n",
    "    \n",
    "\n",
    "top_reviews, reviews_dict = create_reviews_dict(top_recipes['new_recipe_id'])\n",
    "\n",
    "# Sparsity\n",
    "sparsity = len(top_reviews) / (len(top_recipes) * len(top_reviews['member_id'].unique()))\n",
    "\n",
    "print(f\"Sparsity: {sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get largest cluster\n",
    "top_cluster = max(clusters, key=len)\n",
    "print(len(top_cluster))\n",
    "\n",
    "# get the ids in the top cluster\n",
    "top_cluster_ids = [net.vs[node_id]['new_recipe_id'] for node_id in top_cluster]\n",
    "top_cluster_ids\n",
    "\n",
    "# network_reviews, network_reviews_dict = create_reviews_dict(top_recipes['new_recipe_id'])\n",
    "cluster_reviews, cluster_reviews_dict = create_reviews_dict(top_cluster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for the cluster dictionary\n",
    "def create_ratings_df(ratings_dict):\n",
    "    ratings_rows = []\n",
    "    for recipe_id, ratings in ratings_dict.items():\n",
    "        for member_id, rating in ratings:\n",
    "            ratings_rows.append((member_id, recipe_id, rating))\n",
    "\n",
    "    ratings_df = pd.DataFrame(ratings_rows, columns=['member_id', 'recipe_id', 'rating'])\n",
    "    return ratings_df\n",
    "\n",
    "ratings_sample_df = create_ratings_df(cluster_reviews_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD, KNNWithMeans, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Find maximum and minimum rating\n",
    "max_rating = ratings_sample_df['rating'].max()\n",
    "min_rating = ratings_sample_df['rating'].min()\n",
    "print(max_rating, min_rating)\n",
    "\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "\n",
    "data = Dataset.load_from_df(ratings_sample_df, reader)\n",
    "\n",
    "print(data.df.head())\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select user from top cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_uid = 0\n",
    "\n",
    "for (member, recipe, rating) in ratings_sample_df.values: \n",
    "    if recipe in top_cluster_ids and recipe != 9533:\n",
    "        ref_uid = member\n",
    "        break\n",
    "\n",
    "print(int(ref_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tf-idf for description terms to identify similarities between descriptions and as a result similarity between recipes. Given a recipe, suggest others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content-based filtering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_recipes_filtered = top_recipes.dropna(subset=['description'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "item_features = tfidf_vectorizer.fit_transform(top_recipes_filtered['description'])\n",
    "\n",
    "cosine_sim = cosine_similarity(item_features, item_features)\n",
    "\n",
    "top_n_indices = np.argsort(-cosine_sim, axis=1)[:, 1:21]\n",
    "\n",
    "top_n_recipe_ids = top_recipes_filtered['new_recipe_id'].values[top_n_indices]\n",
    "\n",
    "similar_recipes_dict = {recipe_id: top_n_recipe_ids[i].tolist() for i, recipe_id in enumerate(top_recipes_filtered['new_recipe_id'])}\n",
    "\n",
    "list(similar_recipes_dict.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 similar recipes for a specific recipe\n",
    "recipe_id = 205530\n",
    "similar_recipe_ids = similar_recipes_dict[recipe_id]\n",
    "similar_recipe_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recipe entry for the recipe_id\n",
    "recipe = top_recipes_filtered[top_recipes_filtered['new_recipe_id'] == recipe_id]\n",
    "recipe2 = top_recipes_filtered[top_recipes_filtered['new_recipe_id'] == similar_recipe_ids[1]]\n",
    "\n",
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a user recommend a given number of recipes based on what he liked\n",
    "def recommend_recipes(user_id, n_recipes=10):\n",
    "    user_ratings = ratings_sample_df[ratings_sample_df['member_id'] == user_id]\n",
    "\n",
    "    rated_recipe_ids = user_ratings['recipe_id'].values\n",
    "\n",
    "    top_rated_recipes = user_ratings[user_ratings['rating'] > 3]['recipe_id'].values\n",
    "\n",
    "    print(user_ratings)\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for recipe_id in top_rated_recipes:\n",
    "        similar_recipe_ids = similar_recipes_dict[recipe_id]\n",
    "        print(\"AA\", similar_recipe_ids)\n",
    "        for similar_recipe_id in similar_recipe_ids:\n",
    "            if similar_recipe_id not in rated_recipe_ids:\n",
    "                recommendations.append(similar_recipe_id)\n",
    "\n",
    "        if len(recommendations) >= n_recipes * 20:\n",
    "            break\n",
    "\n",
    "    recommendations = top_recipes[top_recipes['new_recipe_id'].isin(recommendations)].sort_values(by='average_rating', ascending=False).head(n_recipes)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "content_normal = recommend_recipes(ref_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering for the top cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_cluster_recipes = top_recipes[top_recipes['new_recipe_id'].isin(top_cluster_ids)]\n",
    "\n",
    "top_recipes_top_cluster_filtered = top_cluster_recipes.dropna(subset=['description'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "item_features = tfidf_vectorizer.fit_transform(top_recipes_top_cluster_filtered['description'])\n",
    "\n",
    "cosine_sim = cosine_similarity(item_features, item_features)\n",
    "\n",
    "top_n_indices = np.argsort(-cosine_sim, axis=1)[:, 1:21]\n",
    "\n",
    "top_n_recipe_ids = top_recipes_top_cluster_filtered['new_recipe_id'].values[top_n_indices]\n",
    "\n",
    "similar_recipes_cluster_dict = {recipe_id: top_n_recipe_ids[i].tolist() for i, recipe_id in enumerate(top_recipes_top_cluster_filtered['new_recipe_id'])}\n",
    "\n",
    "list(similar_recipes_cluster_dict.keys())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_recipes_top_cluster(user_id, n_recipes=10):\n",
    "    user_ratings = ratings_sample_df[ratings_sample_df['member_id'] == user_id]\n",
    "\n",
    "    rated_recipe_ids = user_ratings['recipe_id'].values\n",
    "\n",
    "    top_rated_recipes = user_ratings[user_ratings['rating'] > 3]['recipe_id'].values\n",
    "\n",
    "    top_rated_recipes = np.intersect1d(top_rated_recipes, top_cluster_ids)\n",
    "\n",
    "    print(user_ratings)\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for recipe_id in top_rated_recipes:\n",
    "        similar_recipe_ids = similar_recipes_cluster_dict[recipe_id]\n",
    "        print(\"AA\", similar_recipe_ids)\n",
    "        for similar_recipe_id in similar_recipe_ids:\n",
    "            if similar_recipe_id not in rated_recipe_ids:\n",
    "                recommendations.append(similar_recipe_id)\n",
    "\n",
    "        if len(recommendations) >= n_recipes * 20:\n",
    "            break\n",
    "\n",
    "    # get top recipes based on rating \n",
    "    recommendations = top_recipes[top_recipes['new_recipe_id'].isin(recommendations)].sort_values(by='average_rating', ascending=False).head(n_recipes)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "content_cluster = recommend_recipes_top_cluster(ref_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparition between cluster vs normal content recommendation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_normal[['title', 'description', 'average_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_cluster[['title', 'description', 'average_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying a model to predict the rating for a recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model below (logistic regression) is attempting to predict the average ratings of recipes based on their textual descriptions, and the accuracy metric indicates how well the model fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_recipes_filtered['predicted_rating'] = predicted_ratings\n",
    "\n",
    "top_n_recommendations = top_recipes_filtered.sort_values(by='predicted_rating', ascending=False)[0:10]\n",
    "\n",
    "top_n_recommendations[['recipe_id', 'title', 'predicted_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_id = 189335\n",
    "rating = top_n_recommendations[top_n_recommendations['recipe_id'] == recipe_id]['average_rating']\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans, SVD\n",
    "from surprise import accuracy\n",
    "\n",
    "def calculate_precision_recall(predictions, threshold=4):\n",
    "    tp = fp = fn = 0\n",
    "\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        if est >= threshold: \n",
    "            if true_r >= threshold:\n",
    "                tp += 1  \n",
    "            else:\n",
    "                fp += 1 \n",
    "        else: \n",
    "            if true_r >= threshold:\n",
    "                fn += 1 \n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluate_algorithm(algo, trainset, testset):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    precision, recall, f1 = calculate_precision_recall(predictions)\n",
    "    return algo, rmse, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item based collaborative filtering\n",
    "algo_svd = SVD()\n",
    "algo_knn_item = KNNWithMeans(sim_options={'name': 'cosine', 'user_based': False})\n",
    "algo_knn_item2 = KNNWithMeans(sim_options={'name': 'pearson', 'user_based': False})\n",
    "\n",
    "model_svd, rmse_svd, precision_svd, recall_svd, f1_svd = evaluate_algorithm(algo_svd, trainset, testset)\n",
    "model_knn, rmse_knn, precision_knn, recall_knn, f1_knn = evaluate_algorithm(algo_knn_item, trainset, testset)   \n",
    "model_knn2, rmse_knn2, precision_knn2, recall_knn2, f1_knn2 = evaluate_algorithm(algo_knn_item2, trainset, testset)\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(f\"SVD RMSE: {rmse_svd}\")\n",
    "print(f\"SVD Precision: {precision_svd}\")\n",
    "print(f\"SVD Recall: {recall_svd}\")\n",
    "print(f\"SVD F1: {f1_svd}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN RMSE: {rmse_knn}\")\n",
    "print(f\"KNN Precision: {precision_knn}\")\n",
    "print(f\"KNN Recall: {recall_knn}\")\n",
    "print(f\"KNN F1: {f1_knn}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN2 RMSE: {rmse_knn2}\")\n",
    "print(f\"KNN2 Precision: {precision_knn2}\")\n",
    "print(f\"KNN2 Recall: {recall_knn2}\")\n",
    "print(f\"KNN2 F1: {f1_knn2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User based collaborative filtering\n",
    "algo_knn_user = KNNWithMeans(sim_options={'name': 'cosine', 'user_based': True})\n",
    "algo_knn_user2 = KNNWithMeans(sim_options={'name': 'pearson', 'user_based': True})\n",
    "\n",
    "model_knn_user, rmse_knn_user, precision_knn_user, recall_knn_user, f1_knn_user = evaluate_algorithm(algo_knn_user, trainset, testset)\n",
    "model_knn_user2, rmse_knn_user2, precision_knn_user2, recall_knn_user2, f1_knn_user2 = evaluate_algorithm(algo_knn_user2, trainset, testset)\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN User RMSE: {rmse_knn_user}\")\n",
    "print(f\"KNN User Precision: {precision_knn_user}\")\n",
    "print(f\"KNN User Recall: {recall_knn_user}\")\n",
    "print(f\"KNN User F1: {f1_knn_user}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"KNN User2 RMSE: {rmse_knn_user2}\")\n",
    "print(f\"KNN User2 Precision: {precision_knn_user2}\")\n",
    "print(f\"KNN User2 Recall: {recall_knn_user2}\")\n",
    "print(f\"KNN User2 F1: {f1_knn_user2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict ratings for user-item pairs using a given model. If a user-item pair has a known rating in the input data, it retains that rating, otherwise, it predicts a rating using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_seen = trainset.all_users()\n",
    "items_seen = trainset.all_items()\n",
    "\n",
    "raw_users_seen_ids = [trainset.to_raw_uid(uid) for uid in users_seen]\n",
    "raw_items_seen_ids = [trainset.to_raw_iid(iid) for iid in items_seen]\n",
    "\n",
    "user_test_id = 1\n",
    "\n",
    "# Check if a user is in the training set\n",
    "if user_test_id in raw_users_seen_ids:\n",
    "    print(f\"User {user_test_id} is in the training set\")\n",
    "else:\n",
    "    print(f\"User {user_test_id} is not in the training set\")\n",
    "\n",
    "    user_test_id = min(raw_users_seen_ids, key=lambda x: np.mean([r for (_, r) in trainset.ur[trainset.to_inner_uid(x)]]))    \n",
    "\n",
    "    print(f\" selecting user {user_test_id} instead\")\n",
    "\n",
    "\n",
    "def predict_ratings(model, raw_users, raw_items, data):\n",
    "    predictions = {}\n",
    "    # Add to the predictions dictionary all ratings that were previously known\n",
    "    for user_id, item_id, rating in data.itertuples(index=False):\n",
    "        predictions[(user_id, item_id)] = rating\n",
    "\n",
    "    # Save the predictions to file\n",
    "    with open('predictions.csv', 'w') as f:\n",
    "        for (user_id, item_id), rating in predictions.items():\n",
    "            f.write(f\"{user_id},{item_id},{rating}\\n\")\n",
    "    \n",
    "\n",
    "    for user_id in raw_users:\n",
    "        if user_id == 311157:\n",
    "            print(\"user_id\", user_id)\n",
    "        for item_id in raw_items:\n",
    "            if (user_id, item_id) not in predictions:\n",
    "                prediction = model.predict(user_id, item_id)\n",
    "                predictions[(user_id, item_id)] = prediction.est\n",
    "\n",
    "    with open('final_predictions.csv', 'w') as f:\n",
    "        for (user_id, item_id), rating in predictions.items():\n",
    "            f.write(f\"{user_id},{item_id},{rating}\\n\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item based\n",
    "pred_svd = predict_ratings(model_svd, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)\n",
    "pred_knn = predict_ratings(model_knn, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)\n",
    "pred_knn2 = predict_ratings(model_knn2, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User based\n",
    "pred_knn_user = predict_ratings(model_knn_user, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)\n",
    "pred_knn_user2 = predict_ratings(model_knn_user2, raw_users_seen_ids, raw_items_seen_ids, ratings_sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top-N Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 recommendations for a user from the ones he hasn't rated yet\n",
    "def get_top_n_recommendations(predictions, user_id, data, n=5):\n",
    "\n",
    "    items_not_rated = data[data['member_id'] != user_id]['recipe_id'].unique()\n",
    "    print(len(items_not_rated))\n",
    "\n",
    "    user_predictions = [(iid, pred) for (uid, iid), pred in predictions.items() if uid == user_id and iid in items_not_rated]   \n",
    "\n",
    "    items_rated = data[data['member_id'] == user_id]['recipe_id'].unique()\n",
    "    print(len(items_rated))\n",
    "\n",
    "    user_ratings = [(iid, pred) for (uid, iid), pred in predictions.items() if uid == user_id and iid in items_rated] \n",
    "\n",
    "    print(len(user_predictions))\n",
    "    user_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return user_predictions[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_svd = get_top_n_recommendations(pred_svd, user_test_id, ratings_sample_df,20)\n",
    "top_n_knn = get_top_n_recommendations(pred_knn, user_test_id, ratings_sample_df,20)\n",
    "top_n_knn2 = get_top_n_recommendations(pred_knn2, user_test_id, ratings_sample_df,20)\n",
    "\n",
    "print(\"User ID:\", user_test_id)\n",
    "print(\"--------------------\")\n",
    "print(\"SVD: \", top_n_svd)\n",
    "print(\"KNN: \", top_n_knn)\n",
    "print(\"KNN2: \", top_n_knn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_knn_user = get_top_n_recommendations(pred_knn_user, user_test_id, ratings_sample_df,20)\n",
    "top_n_knn_user2 = get_top_n_recommendations(pred_knn_user2, user_test_id, ratings_sample_df,20)\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(\"KNN User: \", top_n_knn_user)\n",
    "print(\"KNN User2: \", top_n_knn_user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ratings_sample_df ratings distribution\n",
    "plt.hist(ratings_sample_df['rating'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_item_svd = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_svd])][['title', 'description', 'average_rating']]\n",
    "results_item_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_item_knn = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn])][['title', 'description', 'average_rating']]\n",
    "results_item_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_item_knn2 = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn2])][['title', 'description', 'average_rating']]\n",
    "results_item_knn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_user_knn = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn_user])][['title', 'description', 'average_rating']]\n",
    "results_user_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_user_knn2 = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in top_n_knn_user2])][['title', 'description', 'average_rating']]\n",
    "results_user_knn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 498271\n",
    "user_ratings = ratings_sample_df[ratings_sample_df['member_id'] == uid]\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision at k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_liked = top_recipes[top_recipes['new_recipe_id'].isin(user_ratings['recipe_id'])][['title', 'ingredients', 'average_rating']]\n",
    "recipes_liked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svd_user = get_top_n_recommendations(pred_svd, uid, ratings_sample_df, 20)\n",
    "pred_knn_user = get_top_n_recommendations(pred_knn, uid, ratings_sample_df, 20)\n",
    "pred_knn_user2 = get_top_n_recommendations(pred_knn2, uid, ratings_sample_df, 20)\n",
    "pred_svd_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified the following ingredients as relevant: \n",
    "- chicken \n",
    "- tortilla\n",
    "- chips\n",
    "- tomatoes\n",
    "- cheese\n",
    "- spaghetti pasta\n",
    "- pepper\n",
    "- tomato sauce\n",
    "- ground beef\n",
    "- green beans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_svd = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in pred_svd_user])].sort_values(by='average_rating', ascending=False)\n",
    "recipes_svd[['title', 'ingredients', 'average_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_svd['relevant'] = [1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1]\n",
    "recipes_svd[['title', 'relevant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_knn = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in pred_knn_user])].sort_values(by='average_rating', ascending=False)\n",
    "recipes_knn[['title', 'ingredients', 'average_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_knn2 = top_recipes[top_recipes['new_recipe_id'].isin([x[0] for x in pred_knn_user2])].sort_values(by='average_rating', ascending=False)\n",
    "recipes_knn2[['title', 'ingredients', 'average_rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sorted(list(cluster_reviews['last_modified_date']))\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_until_date(reviews, date):\n",
    "    filtered_reviews = reviews[reviews['last_modified_date'] <= date]\n",
    "    return len(filtered_reviews)\n",
    "\n",
    "reviews_until_date(cluster_reviews, dates[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_count = pd.DataFrame([[date, reviews_until_date(cluster_reviews, date)] for date in dates], columns=['Date', 'Count']).drop_duplicates()\n",
    "review_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviews_between_dates(reviews, initial_date, end_date):\n",
    "    filtered_reviews = reviews[(reviews['last_modified_date'] > initial_date) & (reviews['last_modified_date'] <= end_date)]\n",
    "    return len(filtered_reviews)\n",
    "\n",
    "\n",
    "def bin_dates(dataset, bin_size=20): \n",
    "    first_date = dataset['last_modified_date'].min()\n",
    "    last_date = dataset['last_modified_date'].max()\n",
    "\n",
    "    bin_range = (pd.to_datetime(last_date) - pd.to_datetime(first_date)) / bin_size\n",
    "\n",
    "    bins = [pd.to_datetime(first_date) + bin_range * i for i in range(bin_size)]\n",
    "\n",
    "    for i in range(len(bins)):  \n",
    "        bins[i] = bins[i].strftime('%Y-%m-%d')\n",
    "\n",
    "    bins.append(last_date)\n",
    "\n",
    "    return bins  \n",
    "\n",
    "\n",
    "dates = bin_dates(cluster_reviews)\n",
    "\n",
    "binned_reviews = []\n",
    "for i in range(len(dates) - 1):\n",
    "    initial_date = dates[i]\n",
    "    end_date = dates[i + 1]\n",
    "    reviews_count = reviews_between_dates(cluster_reviews, initial_date, end_date)\n",
    "    binned_reviews.append({'start_date': initial_date, 'end_date': end_date, 'review_count': reviews_count})\n",
    "\n",
    "binned_reviews_df = pd.DataFrame(binned_reviews)\n",
    "print(binned_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Count', dpi=100):\n",
    "    plt.figure(figsize=(15,4), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red', )\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(binned_reviews_df, x=binned_reviews_df['start_date'], y=binned_reviews_df['review_count'], title='Temporal Analysis of Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def plot_decompositions(df, label, period=10): \n",
    "    # Multiplicative Decomposition \n",
    "    multiplicative_decomposition = seasonal_decompose(df[label], model='multiplicative', period=period)\n",
    "\n",
    "    # Additive Decomposition\n",
    "    additive_decomposition = seasonal_decompose(df[label], model='additive', period=period)\n",
    "\n",
    "    # Plot\n",
    "    plt.rcParams.update({'figure.figsize': (16,12)})\n",
    "    multiplicative_decomposition.plot().suptitle('Multiplicative Decomposition', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    additive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decompositions(binned_reviews_df, 'review_count', period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decompositions(review_count, 'Count', period=len(review_count) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rating_between_dates(reviews, initial_date, end_date):\n",
    "    filtered_reviews = reviews[(reviews['last_modified_date'] > initial_date) & (reviews['last_modified_date'] <= end_date)]\n",
    "    return filtered_reviews['rating'].mean()\n",
    "\n",
    "def average_rating_until_date(reviews, date):\n",
    "    filtered_reviews = reviews[reviews['last_modified_date'] <= date]\n",
    "    return filtered_reviews['rating'].mean()\n",
    "\n",
    "def bin_dates(dataset, bin_size=20):\n",
    "    first_date = dataset['last_modified_date'].min()\n",
    "    last_date = dataset['last_modified_date'].max()\n",
    "\n",
    "    bin_range = (pd.to_datetime(last_date) - pd.to_datetime(first_date)) / bin_size\n",
    "\n",
    "    bins = [pd.to_datetime(first_date) + bin_range * i for i in range(bin_size)]\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        bins[i] = bins[i].strftime('%Y-%m-%d')\n",
    "\n",
    "    bins.append(last_date)\n",
    "\n",
    "    return bins\n",
    "\n",
    "dates = bin_dates(cluster_reviews, 50)\n",
    "\n",
    "binned_ratings = []\n",
    "\n",
    "for i in range(len(dates) - 1):\n",
    "    initial_date = dates[i]\n",
    "    end_date = dates[i + 1]\n",
    "    average_rating = average_rating_between_dates(cluster_reviews, initial_date, end_date)\n",
    "    binned_ratings.append({'start_date': initial_date, 'end_date': end_date, 'average_rating': average_rating})\n",
    "\n",
    "binned_ratings_df = pd.DataFrame(binned_ratings)\n",
    "print(binned_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_ratings_df['average_rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decompositions(binned_ratings_df, 'average_rating', period=len(binned_ratings_df) // 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
